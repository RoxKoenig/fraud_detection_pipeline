name: MLOps Pipeline for Fraud Detection with Database Connection

on:
  schedule:
    - cron: '0 0 1 * *'  # Run on the 1st of every month
  workflow_dispatch:

jobs:
  pipeline:
    name: Fraud Detection MLOps Pipeline with Database Connection
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      # Restore cached historical data (optional, but usually not needed with artifact use)
      - name: Restore Cached Historical Data
        uses: actions/cache@v3
        with:
          path: data/historical_data.csv
          key: fraud-historical-data-${{ github.run_id }}
          restore-keys: fraud-historical-data-

      # Download previous historical data (artifact)
      - name: Download Historical Data (if available)
        id: download-historical-data
        uses: actions/download-artifact@v4
        with:
          name: historical-data
          path: data/
        continue-on-error: true

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.12.3'

      - name: Install Python dependencies
        run: |
          python -m venv .venv
          source .venv/bin/activate
          pip install --upgrade pip
          pip install -r requirements.txt
          pip install psycopg2

      - name: Install Docker Compose
        run: |
          sudo curl -L "https://github.com/docker/compose/releases/latest/download/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose
          sudo chmod +x /usr/local/bin/docker-compose

      - name: Free Ports 5000 and 5001
        run: |
          for port in 5000 5001; do
            pid=$(sudo lsof -ti :$port) || true
            if [ -n "$pid" ]; then
              sudo kill -9 $pid || true
            fi
          done

      - name: Build and Start Docker Services
        run: |
          docker-compose up --build -d

          # Wait for PostgreSQL readiness
          for i in {1..30}; do
            docker exec fraud_detection_db pg_isready -U admin -d fraud_detection_db && break
            sleep 5
          done

          # Wait for MLflow readiness
          for i in {1..30}; do
            curl --silent --fail http://localhost:5001 && break
            sleep 5
          done

      - name: Show Logs on Failure
        if: failure()
        run: |
          docker logs fraud_detection_db || true
          docker logs mlflow_server || true

      - name: Load Database Backup
        env:
          DB_USER: admin
          DB_PASSWORD: password
          DB_NAME: fraud_detection_db
        run: |
          if [ -f "fraud_detection_db_backup.sql" ]; then
            docker exec -i fraud_detection_db psql -U $DB_USER -d $DB_NAME < fraud_detection_db_backup.sql
          else
            echo "No database backup found, skipping."
          fi

      - name: Run MLOps Pipeline
        env:
          DB_NAME: fraud_detection_db
          DB_USER: admin
          DB_PASSWORD: password
          DB_HOST: localhost
          DB_PORT: 5432
        run: |
          source .venv/bin/activate

          echo "Generating monthly data..."
          python generate_monthly_data.py --month 1 --output_path output.csv

          echo "Detecting data drift..."
          python data_drift.py

          echo "Running main pipeline..."
          python main.py

          echo "Retraining model..."
          python retrain.py

          echo "Deploying model..."
          for port in 5000; do
            pid=$(sudo lsof -ti :$port) || true
            if [ -n "$pid" ]; then
              sudo kill -9 $pid || true
            fi
          done
          python deploy_model.py

      # âœ… Upload updated historical data to artifacts
      - name: Upload Updated Historical Data
        uses: actions/upload-artifact@v4
        with:
          name: historical-data
          path: data/historical_data.csv

      - name: Clean Up Docker Containers
        run: docker-compose down
